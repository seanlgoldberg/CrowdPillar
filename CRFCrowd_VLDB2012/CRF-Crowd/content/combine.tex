\section{Probabilistic Data Integration}

In an ideal world, all the responses coming from the crowd will be correct values equivalent to the ground truth.  We formulate a question, get an answer, and replace fields that were requested.  In practice, there are numerous reasons a single person from the crowd may not supply the correct result.

Services like Amazon Mechanical Turk are subject to spammers that provide random responses in order to reap the benefit of a Human Intelligence Task (HIT) while doing little of the actual work \cite{Panos10}.  A good deal of research has been done to reduce the effect of spammers including repeated labeling \cite{Sheng:2008:GLI:1401890.1401965} and interspersing ground truth to gauge Turker effectiveness \cite{quinn10}.  Even honest Turkers, however, may not always give the correct response for reasons such as lack of knowledge, inexperience, or increased difficulty of the questions.  The golden standard has been to ask the question multiple times and take a majority vote among the users. 

Here we model a new way of looking at the crowd response, viewing it as an application of probabilistic data integration.  In traditional data integration, data is combined from multiple heterogeneous sources to give the user a single, unified view.  Probabilistic data integration attaches probabilities to the combined result.  Generally, there is ambiguity in the compatibility of certain relations which leads to a probability value as a result of combination itself, despite the data being indivudally deterministic.

It's also possible for the data coming from different sources to include probability as a first class citizen, that is, the data is naturally probabilistic, such as the combination of probabilistic sensor data.  Combining results from the crowd becomes an application in probabilistic data integration if we take each Turker to be a source of data and attach probabilities to their answers based on some quality rating.  This quality rating can be something simple like the Turker's approval rating or something more complex.  For instance, Panagiotis et al. \cite{Ipeirotis:2010:QMA:1837885.1837906} build upon a model for recovering worker error rates by Dawid and Skene \cite{dawid79} and are able to separate worker bias to assign a true Turker accuracy.

We employ the machinary of the Dempster-Shafer model of belief functions to combine probabilistic evidence from multiple workers.  The goal is to combine data to present a single unified crowd response for merging with the original CRF output in the PDB.  This second step of combining crowd and CRF can be accomplished using the same method, but treating the total crowd and CRF as different probabilistic sources.

\subsection{Dempster-Shafer Belief Model}
The Dempster-Shafer model \cite{dempster67a, Shafer76} employs a mathematical object called a belief function that measures the degree of belief (or mass) someone has about an event.  The uncertainty associated with a belief corresponds with missing or incomplete data, as opposed to fuzzy or possibilistic data.  Collecting evidence from different sources, one can establish a degree of belief about the reliability of the source itself and therefore also the evidence presented.

Consider an event $X$.  Dempster-Shafer theory maps each element of the power set of $X$ to the interval $[0,1]$.  This mapping is referred to as the \textit{mass function}.  The fundamental properties of the mass function are:

\begin{equation*}
m(\emptyset) = 0
\end{equation*}
\begin{equation*}
\sum_{A\in2^{X}} m(A) = 1
\end{equation*}

That is, the mass of the empty set is always zero and the remaining members of the power set have to sum to 1.

To motivate back to our original problem of information extraction, let's assume binary labelings for a token, $X=\{0,1\}$.  Of the four elements of the power set of X, only 3 have mass functions: m(\{0\}), m(\{1\}), and m(\{0,1\}).  They correspond to the mass that the proper label is 0, that the proper label is 1, or that we are uncertain and the proper label can still be either 0 or 1.

The \textit{belief} in a set is the sum of all elements of the power set that contain that set.  Therefore the belief in label 0 is defined as $m(\{0\})+m(\{0,1\})$, with a similar function for the belief in label 2.  Renormalizing over the beliefs provides a probability distribution over the set of labels.

Mass functions from multiple sources may be combined in a principled manner using Dempster's Rule of Combination.  Let's presume we have two different mass functions $m_{0}$ and $m_{1}$.  The \textit{joint mass} is found with:

\begin{equation*}
\begin{split}
m_{0,1}(\emptyset) &=0\\
%\end{equation*}
%\begin{equation*}
%\begin{split}
m_{0,1}(A) &=(m_{0}\oplus m_{1})(A)\\
                   &=\frac{1}{1-K} \sum_{B\cap C=A\neq\emptyset} m_{0}(B)m_{1}(C)
\end{split}
\end{equation*}

where

\begin{equation*}
K=\sum_{B\bigcap C=\emptyset}m_{0}(B)m_{1}(C)
\end{equation*}

The combination is essentially a normalized outer product.  All combinations with an intersection equal to the event in question are summed.
 
\subsection{Combining Crowd Data}

If multiple Turkers are treated as different sources and their responses as evidence, we can map those responses to belief functions and combine them using the Rule of Combination.  The usual technique is to ask the same question to multiple Turkers and take a majority vote.  While generally effective, there arise situations where the crowd is split on a result.  Possibilities include an image of poor quality or a text analytic question in which the majority of workers are not proficient in English \cite{Rashtchian:2010:CIA:1866696.1866717}.

Let's say that we limit responses to only those Turkers with a 75\% quality rating (that is, they give the correct label 75\% of the time and an incorrect label 25\% of the time) or above and do a best of 5 majority vote.  If three Turkers with an approval rating of 75\% answer label  and two turkers with an approval rating of 100\% answer label 1, the majority vote takes label 1 and passes no other information about who responded with which label.  If a particularly difficult question has Turkers divided, such uncertainties can not be stored and processed in a traditional DB.  Our use of a PDB framework allows the uncertainties to persist and the combination method provides a more reliable estimate of this uncertainty. 

If the crowd gives conflicting  responses to a question, this discrepancy can be reflected within the database by determining the belief we have that each answer is correct.  This is where we make use of the machinery of Dempster-Shafer theory.  For each question submitted, we maintain a running mass function for the correctness of each possible answer.  This function is updated as new responses come in from the crowd.  If there are $n$ possible answers, we are concerned with $n+1$ masses, one for each answer plus the uncertainty mass that the Turker is unreliable and their response is equivalent to a random answer.  


\begin{algorithm}
	\SetAlgoLined
	\KwData{Question $Q$, Turker $T$, Response $R \in [1,n]$}
	\KwResult{$Q.m =$ Total mass for Q}
	\Begin{
		$n \equiv$ number of possible answers to $Q$\;
		$Q.m \equiv$ current mass for Q\;
		Initialize masses $m[1]$,...,$m[n+1]$ to $0$\;
		\tcp{Map response and uncertainty to mass functions}
		$m[R] \leftarrow T.rating$\;
		$m[n+1] \leftarrow 1-T.rating$\;
		\tcp{Check if this is the first response}
		\eIf{$Q.m =$ NULL}{
			\Return{$Q.m \leftarrow m$}		
		}
		{
			Initialize $sum[1]$,...,$sum[n+1]$ to $0$\;
			\For{$p=1$ \KwTo $n+1$}{
				Initialize $K \leftarrow 0$\;
				\For{$i=1$ \KwTo $n+1$}{
					\For{$j=1$ \KwTo $n+1$}{
						\tcp{Take outer product}
						$Outer \leftarrow m[i]*Q.m[j]$\;
						\tcp{Check for intersection}
						\eIf{$i=j$ or $i=n+1$ or $j=n+1$}{
							$sum[p] \leftarrow sum[p]+Outer$\;
						}
						{
							$K \leftarrow K+Outer$\;
						}
					}
				}
				\tcp{Renormalization}
				$sum[p] \leftarrow (\frac{1}{1-K})*sum[p]$\;
			}
			\Return{$Q.m \leftarrow sum$}
		}
	}
	\caption{Update Answer Belief}
	\label{DSCombo}
\end{algorithm}

Algorithm \ref{DSCombo} displays the pseudocode for updating a question's current mass function with a new response provided by the Turker. We assume the response takes the form of a multiple choice answer and ranges from $1$ to $n$.  The mass function associated with the Turker is zero for every answer except the one they chose, which gets mapped to their quality rating in $[0,1]$.  This defines the likelihood they picked the correct answer.  Their unreliability gets mapped to the set of all possible answers $m[n+1]$.

If there is no current mass associated with the question, the current Turker mass is taken as the Question's mass.  Otherwise, we need to combine the two masses using Dempster's Rule of Combination.  Remember that the combination for each answer is an outer product over all sets that have an intersection equivalent to that answer.  Here we assume mutual exclusivity among all choices and so this intersection occurs only when $m$ and $Q.m$ are the same answer or either is the set of all possible answers.  The final result is a newly combined mass function which can easily be converted into a probability distribution for that question and integrated back into the PDB.

\subsection{Combining Crowd and Machine}

After combining multiple answers from the crowd, the total crowd response needs to be aggregated with the original graphical model output.  One method is to completely eliminate the machine response and simply put the crowd data in its place.  Given the increased reliability of human authors, this can lead to desirable results.

We take a differing view, however, like a detective collecting evidence from different sources.  The PGM and crowd represent merely two different sources from which conclusions are being drawn.  Rather than throwing away information, we seek to ML and crowd answers in the same principled way.  On questions in which the crowd is divided amongst itself, we can use the original PGM to "break the tie".

The combination of crowd and machine is the same as Algorithm \ref{DSCombo}, except that that there exists no analog to the quality rating in the machine output.  While a confidence value can be attributed to a measure of certainty, it is not necessarily true that the complement is a measure of randomness.  The simple method is to forego the use of a quality rating and uncertainty metric and map the confidence values for each label directly to its associated mass function.  The label confidence from a CRF can be attributed from the marginal probabilities \cite{Kristjansson:2004:IIE:1597148.1597216}. 

The final result is a complete mass function which can easily be converted into a probability distribution.
